{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbUMltrRQJ37",
        "outputId": "98558499-415d-4adc-a1d1-bd12dd0a94c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Accuracy  Precision    Recall  Type I Error  \\\n",
            "Logistic Regression  0.923077   0.931507  0.957746      0.151515   \n",
            "Decision Tree        0.961538   1.000000  0.943662      0.000000   \n",
            "Random Forest        1.000000   1.000000  1.000000      0.000000   \n",
            "Gradient Boosting    0.971154   1.000000  0.957746      0.000000   \n",
            "SVM                  0.682692   0.682692  1.000000      1.000000   \n",
            "KNN                  0.855769   0.951613  0.830986      0.090909   \n",
            "\n",
            "                     Type II Error  \n",
            "Logistic Regression       0.042254  \n",
            "Decision Tree             0.056338  \n",
            "Random Forest             0.000000  \n",
            "Gradient Boosting         0.042254  \n",
            "SVM                       0.000000  \n",
            "KNN                       0.169014  \n",
            "Z-Test for Mean Age Difference: Z-Statistic=1.7686101020183942, P-Value=0.07695896375275615\n",
            "Z-Test for Type II Error between SVM and KNN: Z-Statistic=nan, P-Value=nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/statsmodels/stats/weightstats.py:1554: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  var /= nobs1 + nobs2 - 2 * ddof\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from statsmodels.stats.weightstats import ztest\n",
        "df = pd.read_csv(\"/content/diabetes_data_upload.csv\")\n",
        "label_encoders = {}\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "        label_encoders[col] = le\n",
        "X = df.drop(columns=[\"class\"])\n",
        "y = df[\"class\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"SVM\": SVC(probability=True),\n",
        "    \"KNN\": KNeighborsClassifier()\n",
        "}\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "    type_i_error = fp / (fp + tn)\n",
        "    type_ii_error = fn / (fn + tp)\n",
        "\n",
        "    results[name] = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"Type I Error\": type_i_error,\n",
        "        \"Type II Error\": type_ii_error\n",
        "    }\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df)\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred = log_reg.predict(X_test)\n",
        "misclassified_indices = (y_test != y_pred)\n",
        "correctly_classified_ages = X_test.loc[~misclassified_indices, \"Age\"]\n",
        "misclassified_ages = X_test.loc[misclassified_indices, \"Age\"]\n",
        "z_stat, p_value = ztest(correctly_classified_ages, misclassified_ages)\n",
        "print(f\"Z-Test for Mean Age Difference: Z-Statistic={z_stat}, P-Value={p_value}\")\n",
        "rf_fp_rate = results[\"Random Forest\"][\"Type I Error\"]\n",
        "if rf_fp_rate > 0.20:\n",
        "    z_stat, p_value = ztest([rf_fp_rate], value=0.20)\n",
        "    print(f\"Z-Test for Type I Error in Random Forest: Z-Statistic={z_stat}, P-Value={p_value}\")\n",
        "z_stat, p_value = ztest([results[\"SVM\"][\"Type II Error\"]], [results[\"KNN\"][\"Type II Error\"]])\n",
        "print(f\"Z-Test for Type II Error between SVM and KNN: Z-Statistic={z_stat}, P-Value={p_value}\")\n"
      ]
    }
  ]
}